---
title: "Use of some functions in package 'ipv'"
author: "F. Tusell"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(cache=TRUE, fig.width=7, fig.height=5.5)
options(width=120)
```


In the process of constructing a housing price index for the Basque Autonomous Community (CAPV) and certain of its subareas using real estate data from web sources (mainly idealista.com), it has been necessary to write a number of functions, which are now collected in package `ipv`.

These are spur-of-the-moment functions, which are usable and in fact have supported our work; but they lack de degree of polish and checking that oen would expect from a carefuly planned and designed package.


## Datos

The data have been collected in two `.rda` files,  `venta.dep.rda` and `alquiler.dep.rda`.
We have cleanned the raw data as made available to us by removing anomalous or repeated observations, etc. The files reside in the `data` folder of the package and can be loaded
by typing:


```{r}
library(ipv)
data("venta.dep")
data("alquiler.dep")
```

(*Beware*: if you are using a publicly available version of this package, such data may have been obscured, distorted and shuffled to preserve confidentiality. You will not be able to reproduce the results in this vignette, although the data provided will suffice to test
the use of functions.)


Other than package `ipv` we will need those following: all of them can be obtained from CRAN.

```{r}
library(mgcv)
library(tidyverse, verbose=FALSE)
library(sp)
library(rgdal)
library(rgeos)
library(spgwr)
library(zoo)
```

## Model estimation


The package targets two types of models for housing prices index estimation:

1. Global models plus non-parametric tendency: these are models where parameters of the hedonic part are common to the whole area of estimation.
Location does matter in prices, but it enters the model via a proxy like `SUBREGION`, `AF` (functional area), etc.
The general form of a global model would be:
$$ \log(\textrm{Precio/m2})_{it} = \sum_{j=1}^K\beta_jx_{ij} + \sum_{l=1}^L\beta_{l}\textrm{loc}_{il} + s(t) + \epsilon_{i} $$
$\textrm{loc}_{il}$ is a dummy which takes value 1 if observation 
$i$ belongs to region $l$, cero otherwise; $\beta_l$ measures the impact 
on the response of the fact that the dwelling  
is in region $l$, and $s(t)$ is a non-parametric function of time global 
to all regions, from which the index computed. 

2. Geographically weighted regression models (GWR) plus non-parametric trend: 
these are models where the parameters change across the space.
The effect in the price of a dwelling of including a garage, for instance, is not the same across space, and the model takes these into account. The general form of a GWR witt non-parametric trend is:
$$ \log(\textrm{Precio/m2})_{it} = \sum_{j=1}^K\beta_j(u_i,v_i)x_{ij}  + s(t) + \epsilon_{i} $$
Here the location dummies have disappeared and the betas of the hedonic part are dependent on the coordinates
$u_i,v_i$. The lcoation dummies are no longer present, as the space effect is taken up via the dependence of 
the betas on coordinates $(u_i,v_i)$.

Both types of models have a hedonic part for quality correction and a non-parametric tendency, from which the price index is derived. Although not imperative, it makes more sense to take prices in the log scale and per unit of surface (square foot or square meter) of the dwelling.

We prepare the data computing the log price per unit of surface, an auxiliary time variable `x` 
(days elapsed from the 
date of the oldest observation in the sample) and filtering out observations for which no geographical information is available in coordinates `DX_ETRS89` and `DY_ETRS89`:

```{r PrepDatos}
datos <- venta.dep %>% 
  mutate( logpm2 = log(IMP_CREACION / NUM_SUPERF),
          x = as.integer(FEC_CREACION - min(FEC_CREACION)) ) %>%
  filter( !is.na(DX_ETRS89) & !is.na(DY_ETRS89)) %>%
  as.data.frame()
```

Geographical coordinates are not needed in a global model, but are required for a GWR model.

### Global models

Global models are estimated using function `gam`. For instance,


```{r ModeloGlobal}
mod1 <- gam( logpm2 ~   SUBREGION + ROOMNUMBER + HASLIFT + 
                HASGARDEN + HASSWMMINGPOOL + HASTERRACE + 
                IND_GARAJE  + s(x,bs="cr", k=16), 
              data=datos)
```

It is up to the analyst to decide which variables to include. Clearly, we want a model as descriptive as posible,
incorporating each variable which conceivably is descriptive of the quality of the dwellings; however, too ambitious a model will force to discard many observations for which the included variables are not observed. The `k` parameter
is the equivalent number of degrees of freedom (EDF): we have found one or two per year to be plenty.
`s(x, bs="cr", k=16)` is a cubic **spline** with the prescribed degrees of freedom.

Results can be inspected by:

```{r, ResultadosModeloGlobal}
summary(mod1)
anova(mod1)
```


#### ConsInd

The object returned by `gam` is all we need to compute the index, using function  `ConsInd`:

```{r, ZonasViaSUBREGION}
ind <- ConsInd(modelo=mod1, base="2007-12-31", 
        tit="Índice precio vivienda CAPV.\nEf. espacial: SUBREGION",
        fechas=as.Date(datos$FEC_CREACION),
        plot=TRUE)
```

Even though the desired result will most often be the graph,  `ConsInd` returns also (invisibly)
the index, as a time series with daily dates.

```{r}
class(ind)
head(ind)
```

#### IndZonas

Podemos desear ajustar índices a diferentes ámbitos. La función `IndZonas`
simplifica el trabajo: en lugar de una invocación a `ConsInd` para cada
ámbito ---por ejemplo, para cada Territorio Histórico--- podemos hacer una 
sóla invocación a `IndZonas` dando una variable `zonas` cuyos niveles 
especificaran cada uno de los ámbitos para los que se calcula un índice.

We might want to compute indeices for diferent zones. Function `IndZonas` is meant to simplify 
the task: rather than a separate invocation to `ConsInd` for each zone, we can make a single
invocation to `IndZonas` passing an argument `zonas` whose levels define the different zones.

Hence, if we want a separate index for each province,

```{r}
ind.prov <- IndZonas(datos, zonas="PROVINCIA", frm=formula(mod1))
```

No es preciso que proporcionemos toda la información obtenida al estimar 
el modelo `mod1`: basta con la fórmula, que podemos extraer de `mod1` o 
directamente teclear. Una invocación equivalente a la anterior, sería:

We have taken the model specification formn `mod1`; we could type it directly.
The following invocation would be functionally equivalente to the previous
one:

```{r}
ind.prov <- IndZonas(datos, zonas="PROVINCIA", 
                     frm=formula( logpm2 ~ SUBREGION + ROOMNUMBER + 
                                    HASLIFT + HASGARDEN + HASSWMMINGPOOL +
                                    HASTERRACE +  IND_GARAJE  + 
                                    s(x,bs="cr", k=16) ))
```

The result in  `ind.prov` is *a list* of indices which can be represente in separate panels.


#### mggplot

Plotting several indices is facilitated by using the function `mggplot`, which takes the object 
returned by `IndZones` and constructs the plot. Below we obtain the names of the plots from 
the names in the list `ind.prov`, but we could supply different names in the argument `columnas`.


```{r}
prov <- names(ind.prov)
prov
mggplot(ind.prov, columnas=prov)   
```

We might opt for plotting all indices in a single scale:

```{r}
mggplot(ind.prov, columnas=prov, tipo="multiple")   
```


### Geographically weighted models


The dataframes `venta.dep` and `alquiler.dep` include UTM projected coordinates
(`DX_ETRS89`, `DY_ETRS89` and
corresponding `DX_ED50` and `DY_ED50`) We can set directly a desired *bandwidth* or select it
by cross-validation, which with objects the size of the ones we have here would be quite expensive.
We will set a bandwidth of 5000m; this is the radius of the circles around each point which receive substantial weight
in the local fitting procedure.

Lets create an spatial data frame with the variables we will need:

```{r, CreacionSpatialDataFrame}
datos$HASLIFT <- as.factor(datos$HASLIFT)
spdatos <- datos[,c("logpm2","SUBREGION","ROOMNUMBER","HASLIFT",
                    "HASGARDEN","HASSWMMINGPOOL","HASTERRACE",
                    "IND_GARAJE","DX_ETRS89","DY_ETRS89","FEC_CREACION")]
spdatos <- spdatos[complete.cases(spdatos),]
coordinates(spdatos) <- ~ DX_ETRS89 + DY_ETRS89
```


The *backfitting* algorithm alternates the spatial and time adjustments until convergence. **For ilustration only a subsample is selected here, to reduce computation time. Results with the whole sample chage considerably.** 

```{r, BackFitting-Global}
frm         <- formula(mod1)
frm.param   <- update(frm, ~ . - s(x,bs="cr",k=16))
smooth.term <- 's(x,bs="cr",k=16)'

sel <- ((1:nrow(datos)) %% 5) == 0                        # One observation out of each 5
sel <- sel & datos$FEC_CREACION > as.Date("2006-12-31")   # Only after this date there is enough data

indice <- BackFitting(frm.param=frm.param,
            smooth.term=smooth.term,
            var.loc="SUBREGION",
            coords=c("DX_ETRS89","DY_ETRS89"),
            datos=datos[sel,],
            var.fecha='FEC_CREACION',
            baseday='2008-01-01')
```

The result is

```{r}
plot(indice)
```

El resultado anterior corresponde a un modelo en que la parte paramétrica presenta 
variación espacial (gracias al empleo de GWR), mientras que la parte no paramétrica (que da lugar al índice) es común al ámbito completo. La función `BackFittingLocal` permite 
la estimación de índices para ubicaciones concretas, cuyas coordenadas se pasan en el argumento `cal.pts`. Hay que señalar un segundo *bandwitdh*, `bws`, que puede o no coincidir con el `bw` empleado en la GWR.

Seleccionaremos como puntos de cálculo de índices locales los centroides de barrios que parecen haber registrado una evolución diferente:

```{r, CreacionPuntosIndLocal}
# barrios <- c("Indautxu", "Abando - Albia", "Deusto")
# cal.pts <- matrix(0,length(barrios),2)
# b    <- venta.dep[venta.dep$BARRIO %in% barrios, ]
# dimnames(cal.pts) <- list(barrios, NULL)
# for (i in barrios) {
#   cal.pts[i,] <- apply(b[b$BARRIO==i, c("DX_ETRS89","DY_ETRS89")], 2, FUN="median", na.rm=TRUE)
# }
# cal.pts

xy <- data.frame(ID=c("PlazaEnsanche","GeneralEguia"),
                 X=c(-2.931413,-2.946283),
                 Y=c(43.263538,43.259257))
coordinates(xy) <- c("X","Y")
proj4string(xy) <- CRS("+proj=longlat +datum=WGS84") 
res <- spTransform(xy, CRS("+proj=utm +zone=30 ellps=WGS84"))
res <- as.data.frame(res)
cal.pts <- as.matrix(res[,c("X","Y")])
rownames(cal.pts) <- res[,"ID"]
```

Podemos ahora calcular varios índices locales así:

```{r, BackFittingLocal}
# 
#  Eliminación de observaciones muy lejos de Bilbao
#
sel <- (datos$DX_ETRS89 > 504000) & (datos$DX_ETRS89 < 506000)
sel <- sel & (datos$DY_ETRS89 > 4788000) & (datos$DX_ETRS89 < 4791000)
sel <- sel & datos$FEC_CREACION > as.Date("2010-12-31")   # Sólo donde hay datos suficientes

lista.ind <- BackFittingLocal(frm.param=frm.param,
                        smooth.term='s(x,bs="cr",k=9)',
                        cal.pts=cal.pts,
                        datos=datos[sel,],
                        coords=c("DX_ETRS89","DY_ETRS89"),
                        var.fecha='FEC_CREACION',
                        var.loc='SUBREGION',
                        baseday="2010-12-31",
                        bw=500,
                        bws=200,
                        tol=0.005,
                        plotind=FALSE)
```


```{r}
names(lista.ind[[2]]) <- rownames(lista.ind[[1]])
p <-mggplot(lista.ind[[2]], columnas=rownames(lista.ind[[1]]), tipo="multiple")
p <- p + ggtitle("Local indices",
              sub=paste("Base: ","31-12-2010"," = 100"))
# pdf(file="localindices.pdf")
print(p)
# scratch <- dev.off()
```


### Local indices via time slicing

Am alternative way to the computation of local indices would be time slicing. Using this approach, 
for each location we would do the following:

1. Set the calibration point (location for which the index is sought).
1. Slice observations according to time. The time intervals need be such that enough observations are
left in each slice to allow the fitting of GWR model.
1. With observations in each slice, fit the GWR model at the selected location. 
$$ \log(\textrm{Precio/m2})_{it} = \sum_{j=1}^K\beta_j(u_i,v_i,t)x_{ij}  + \epsilon_{i} $$
This gives a set of 
$\beta(u,v,t)$, where $t$ corresponds to the time slice.
1. With a set of such indices, we can estimate the price at time $t$ 
of a dwelling of given attributes $x_j$ by 
$$\sum_{j=1}^K\beta_j(u_i,v_i,t)x_{j}.$$
Such dwelling would have cost at the base time $t=0$
$$\sum_{j=1}^K\beta_j(u_i,v_i,0)x_{j};$$
hence an estimate of the price index $I_0(t)$ at time $t$ with base period $t=0$ can be constructed as
$$I_0(t) = \frac{\exp{\left(\sum_{j=1}^K\beta_j(u_i,v_i,t)x_{j}\right)}}{\exp{\left(\sum_{j=1}^K\beta_j(u_i,v_i,0)x_{j}\right)}}$$
This is just a Laspeyres type of index in which the shadow prices of the attributes 
(the $\beta_j(u_i,v_i,t)$) are given weights equal to their "presence" $x_j$ in a
virtual homogeneous dwelling, which is taken as representative of the area
(but need not have been observed at all times, nor even at a single time!).

We select data in the Bilbao area, from 2012 onwards (observations before 
are scarce)

```{r}
knitr::knit_exit()
SlicedIndex <-
  function(cal.pts,
           spdatos = NULL,
           from = NULL,
           to = NULL,
           base = NULL,
           frm = NULL,
           vars = NULL,
           bw = 1000,
           area.radius = 5 * bw,
           date = NULL,
           slice.by = NULL)
  {
    require(zoo)
    if (is.null(date))
      stop("'date' not specified with no default.")
    if (is.null(slice.by))
      stop("'slice.by' not specified with no default.")
    #
    # Convert observations to selected time interval
    #
    spdatos@data[, date] <- sapply(spdatos@data[, date], FUN = slice.by)
    spdatos <- spdatos[(spdatos@data[, date] >= from) &
                         (spdatos@data[, date] <= to), ]
    #
    # Pick only required variables, and cases complete for such variables
    #
    spdatos <- spdatos[complete.cases(spdatos@data), ]
    slices  <- sort(unique(spdatos@data[, date]))
    #
    # For each calibration point, take a subset of observations within
    # area.radius distance (projected coordinates are assumed)
    #
    xy      <- coordinates(cal.pts)
    preds   <- as.data.frame(matrix(0, length(slices), nrow(cal.pts)))
    colnames(preds) <- rownames(cal.pts)
    preds   <- zoo(preds, order.by = slices)
    
    for (i in nrow(cal.pts)) {
      sel <- rep(FALSE, nrow(spdatos@data))
      sel <- sel | (colSums((t(coordinates(spdatos)) - xy[i, ]) ^ 2) <
                      area.radius ^ 2)
      for (j in seq_along(slices)) {
        subsel <- sel & (spdatos@data[, date] == slices[j])
        cat("Processing slice:  ", as.character(slices[j]), "\n")
        cat(sum(subsel), "\n")
        preds[j, ] <- gwr(
          formula = frm,
          bandwidth = bw,
          data = spdatos[subsel, ],
          fit.points = cal.pts,
          predict = TRUE
        )$SDF@data$"(Intercept)"
      }
    }
    return(preds)
  }
```



The points for which we want predictions must be in the form of a data frame
with complete values of the variables used in the model. The easiest way to
construct values for the argument `fit.points` below is to take arbitrary rows
of `spdatos` (one for calibration point), replace the values of the variables
for the ones we want, and the set the coordinates conveniently. We use as a
"median house" for this area a flat with three bedrooms, garage space and
elevator, but no garden, swimming pool or terrace ---the first two attributes
being non-existent in the area---.

```{r}
median.houses <- spdatos@data[1:2,]
median.houses$ROOMNUMBER <- 3
median.houses$HASLIFT <- factor("SI", levels=levels(spdatos@data$HASLIFT))
median.houses
```

Now we set the coordinates:

```{r}
coordinates(median.houses) <- cal.pts
```

We will fit a model to each slice of time, and obtain predictions of the prices for the median houses:



```{r}
preds <- SlicedIndex(
    cal.pts = median.houses,
    spdatos = spdatos,
    from = as.yearqtr("2016 Q1"),
    to = as.yearqtr("2019 Q1"),
    bw = 1000,
    frm = formula(logpm2 ~ ROOMNUMBER + 
                    HASLIFT + IND_GARAJE),
    date = "FEC_CREACION",
    slice.by=as.yearqtr)
plot(exp(preds))
```
